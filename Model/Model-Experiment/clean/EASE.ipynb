{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "torch.set_printoptions(sci_mode=True)\n",
    "\n",
    "DATA_PATH = '/opt/ml/final-project-level3-recsys-05/Model/Model-Experiment/data'\n",
    "MODEL_PATH = '/opt/ml/final-project-level3-recsys-05/Model/Model-Experiment/model'\n",
    "VAL_TO_IDX_DATA_PATH = '/opt/ml/final-project-level3-recsys-05/Model/Model-Server/data'\n",
    "\n",
    "PICKLE_PROTOCOL = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EASE():\n",
    "    def __init__(self, reg):\n",
    "        self.reg = reg\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    def clear_memory(self):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = X.to(self.device)\n",
    "        G = X.t() @ X\n",
    "        diagIndices = torch.eye(G.shape[0]) == 1\n",
    "        G[diagIndices] += self.reg\n",
    "\n",
    "        P = G.inverse()\n",
    "        B = P / (-1 * P.diag())\n",
    "        B[diagIndices] = 0\n",
    "\n",
    "        self.B = B.cpu()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        output = (X.to(self.device) @ self.B.to(self.device)).cpu()\n",
    "        return output\n",
    "\n",
    "def get_hit(pred_list, true_list):\n",
    "    hit_list = set(true_list) & set(pred_list)\n",
    "    hit = len(hit_list) / len(true_list)\n",
    "    return hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(os.path.join(VAL_TO_IDX_DATA_PATH, 'clean_problem_id_to_idx.json'), 'r', encoding = 'utf-8') as f:\n",
    "    problemId_to_idx = json.load(f)\n",
    "\n",
    "with open(os.path.join(VAL_TO_IDX_DATA_PATH, 'clean_idx_to_problem_id.json'), 'r', encoding = 'utf-8') as f:\n",
    "    idx_to_problemId = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.read_csv(os.path.join(DATA_PATH, 'user.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_problems_to_idx(problems):\n",
    "    problems = eval(problems)\n",
    "    ret = []\n",
    "    for problemId in problems:\n",
    "        try: ret.append(int(problemId_to_idx[problemId]))\n",
    "        except: continue\n",
    "    return ret\n",
    "\n",
    "user_df['problems_to_idx'] = user_df['problems'].apply(lambda x : get_problems_to_idx(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_df = user_df[user_df['problems_to_idx'].apply(lambda x : True if len(x) >= 15 else False)].reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name_to_idx = {}\n",
    "\n",
    "for idx, user_name in enumerate(new_user_df['user_name'].tolist()):\n",
    "    user_name_to_idx[user_name] = idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = torch.zeros(size = (len(user_name_to_idx), len(problemId_to_idx)))\n",
    "valid_dict = {}\n",
    "\n",
    "group_df = new_user_df.groupby('user_name')\n",
    "\n",
    "for user_name, df in group_df:\n",
    "    random.seed(22)\n",
    "    total = df['problems_to_idx'].values[0]\n",
    "    valid = random.sample(total, 10)\n",
    "    train = list(set(total) - set(valid))\n",
    "    \n",
    "    mat[user_name_to_idx[user_name], train] = 1\n",
    "\n",
    "    valid_dict[user_name_to_idx[user_name]] = valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:36<03:03, 36.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg: 100000 | hit : 0.44241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [01:08<02:20, 35.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg: 10000 | hit : 0.52588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [01:40<01:42, 34.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg: 1000 | hit : 0.54956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [02:12<01:07, 33.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg: 100 | hit : 0.54771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [02:44<00:33, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg: 10 | hit : 0.53965\n"
     ]
    }
   ],
   "source": [
    "for reg in tqdm([100000, 10000, 1000, 100, 10, 1]):\n",
    "    model = EASE(reg = reg)\n",
    "    model.fit(mat)\n",
    "    model.clear_memory()\n",
    "\n",
    "    output = model.predict(mat)\n",
    "    model.clear_memory()\n",
    "\n",
    "    output[mat == 1] = -np.Inf\n",
    "    rec_list = output.argsort(dim = 1)\n",
    "\n",
    "    hit = 0\n",
    "    for idx, rec in enumerate(rec_list):\n",
    "        pred = rec.cpu().numpy().tolist()[::-1][:10]\n",
    "        true = valid_dict[idx]\n",
    "        hit += get_hit(pred, true)\n",
    "\n",
    "    hit /= len(output)\n",
    "    print(f'reg: {reg} | hit : {hit:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = torch.zeros(size = (len(user_name_to_idx), len(problemId_to_idx)))\n",
    "\n",
    "group_df = new_user_df.groupby('user_name')\n",
    "\n",
    "for user_name, df in group_df:\n",
    "    total = df['problems_to_idx'].values[0]\n",
    "    mat[user_name_to_idx[user_name], total] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 1000\n",
    "model = EASE(reg = reg)\n",
    "model.fit(mat)\n",
    "model.clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(MODEL_PATH, 'clean-ease.pickle'), 'wb') as file:\n",
    "    pickle.dump(model, file, protocol = PICKLE_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
